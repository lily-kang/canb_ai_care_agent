import json
import os
from datetime import datetime
from google.adk.models.lite_llm import LiteLlm
from google.adk.agents import LlmAgent, ParallelAgent, SequentialAgent
from google.adk.agents.base_agent import BaseAgent
from google.adk.events.event import Event
from google.adk.events.event_actions import EventActions
from google.genai import types
from google.adk.agents.readonly_context import ReadonlyContext
from google.adk.utils.instructions_utils import inject_session_state
from .prompt import COUNSELING_GENERATOR_PROMPT
from typing import List
from google.adk.agents.callback_context import CallbackContext
from google.adk.models.llm_request import LlmRequest
from sp_agent.utils.performance_logger import get_tracker, log_performance_summary
from sp_agent.tools import (
    load_text_file,
    extract_yaml_case_rules,
    build_or_get_summary_from_state,
)
import logging
from .schema import first_schema, second_schema, third_schema, fourth_schema

logger = logging.getLogger(__name__)

## ëª¨ë¸ ì„¤ì •
# Provider/model
MODEL_GPT_5 = "openai/gpt-4.1" 
MODEL_GEMINI = "gemini-2.5-flash"


async def build_counseling_base_context(readonly_ctx: ReadonlyContext) -> dict:
    """
    Build and cache the shared counseling context used by all sections.

    Returns a dict with:
      - case_code: selected case code string
      - case_guideline: YAML rules text for the case
      - summary_str: JSON string summary of student data
    """
    state = readonly_ctx.session.state

    # 1) Parse case_code from `result` in session state.
    # case_selector_agent is expected to output a plain string case code.
    raw_result = state.get("result")
    case_code = raw_result.strip().strip('"') if isinstance(raw_result, str) else ""
    if not case_code:
        # Fallback: leave a sentinel so it's obvious in the prompt
        case_code = "UNKNOWN_CASE_CODE"

    # 2) Compute compact student summary and store into session state.
    #    This now uses per-session JSON from session state (feature_json/raw_json),
    #    not static files, and reuses any existing cached summary if available.
    try:
        summary_str = build_or_get_summary_from_state(readonly_ctx)
    except Exception as e:
        logger.error("Failed to compute student summary from session state: %s", e)
        summary_str = "{}"

    # 3) Knowledge fileì„ ë¡œë“œí•˜ê³  case_codeì— í•´ë‹¹í•˜ëŠ” ê·œì¹™ë§Œ ì¶”ì¶œ
    yaml_text = load_text_file("sp_agent/knowledge/case_guides.yaml")
    try:
        case_guideline = extract_yaml_case_rules(yaml_text, case_code)
    except Exception:
        # If extraction fails, keep a clear placeholder
        case_guideline = f"[No rules found for case_code={case_code}]"

    return {
        "case_code": case_code,
        "case_guideline": case_guideline,
        "summary_str": summary_str,
    }


# === Section-specific instruction builders ===

async def build_instruction_avoided_and_overall(readonly_ctx: ReadonlyContext) -> str:
    """
    Build instruction for the combined 'ì§€ì–‘ í‘œí˜„' + 'ì´í‰' section.
    """
    context = await build_counseling_base_context(readonly_ctx)
    case_code = context["case_code"]
    case_guideline = context["case_guideline"]
    summary_str = context["summary_str"]

    return f"""
You generate ONLY the 'ì§€ì–‘ í‘œí˜„' and 'ì´í‰' sections of a CANB counseling guide in Korean.

Follow these rules:
- Use [Student Data] as the primary source.
- Use [Case Guides] only for tone, focus, and strategy hints.
- Do NOT copy example sentences from [Case Guides].
- Do NOT mention case_code or case_name explicitly.

Section (0) ì§€ì–‘ í‘œí˜„:
- Provide exactly 2 example sentences, but do NOT wrap them in quotation marks.  
e.g. ì´ ê³¼ëª© ë•Œë¬¸ì— ì ìˆ˜ê°€ ë–¨ì–´ì¡Œì–´ìš”., ì—¬ê¸°ê°€ í‘í¬ë‚¬ë„¤ìš”.
- 1 to 2 sentences explaining what to avoid.

Section (1) ì´í‰:
- Bullet format. 5 to 6 sentences. 
- All bullet sentences MUST start with "-" (a hyphen, No other bullet symbols "â€¢")
- Use noun-ending style (â€œ~íë¦„ì„â€, â€œ~ìƒíƒœì„â€).  
- Include: performance trend vs previous test, subject balance, READi, Alex, attendance, interpretation of current performance.  
- If any metric such as READi, Alex, or reading count is â€œ0â€ or empty, interpret it as â€œThe student is considered to have done little or no activityâ€, Never use the expressions â€œmissing data,â€ â€œno data,â€ or â€œinsufficient information.â€
- IMPORTANT: In 'ì´í‰', wrap the most important phrases with double asterisks to emphasize critical points.
- If the current exam is MT3 or Term Test, DO NOT compare its score with previous MT tests
- Interpret score changes under 15 points as normal variation, and score changes of 15 points or more as meaningful; never call a â‰¥15 change â€œì†Œí­/ê²½ë¯¸í•œâ€.
- Terminology Rule : 1) Do not use 'ì†Œí­'. 2) READi ìˆ˜í–‰ë¥  3) If the data is empty or zero in Alex & READi, do NOT describe it as â€œno dataâ€ or â€œmissing information.â€. Interpret it as â€œìµœê·¼ í™œë™ì´ ì´ë£¨ì–´ì§€ì§€ ì•Šì•˜ìŒ.â€

Output requirements:
- Output MUST be valid JSON.
- No markdown code fences, no comments.
- Return this exact JSON shape:
{{
  "sections": {{
    "avoid": {{
      "id": "avoid",
      "title": "ì§€ì–‘ í‘œí˜„",
      "avoid_example": ["...", "..."],
      "avoid_summary": "..."
    }},
    "summary": {{
      "id": "summary",
      "title": "ì´í‰",
      "content": "..."
    }}
  }}
}}

Below is the information required for generating the counseling script.

[Case Code]
{case_code}

[Case Guides]
{case_guideline}

[Student Data]
{summary_str}
"""


async def build_instruction_data_guide(readonly_ctx: ReadonlyContext) -> str:
    """
    Build instruction for the 'ë°ì´í„° í•´ì„ ê°€ì´ë“œ' section.
    """
    context = await build_counseling_base_context(readonly_ctx)
    case_code = context["case_code"]
    case_guideline = context["case_guideline"]
    summary_str = context["summary_str"]

    return f"""
You generate ONLY the 'ë°ì´í„° í•´ì„ ê°€ì´ë“œ' section in Korean.

Use [Student Data] as the numeric source and [Case Guides] as tone/style guidance.
Do NOT copy example sentences and do NOT mention case_code/case_name.

### LEVEL-BASED SUBJECT RULE
Use the student's level from [Student Data] to decide **which subjects to output**.
- Penta Level:
  subjects = [ "Phonics", "Reading" ]
  + always include: [ "READi", "Alex" ]

- Hexa Level:
  subjects = [ "Listening", "Reading", "Vocabulary" ]
  + always include: [ "READi", "Alex" ]
  (NO Grammar)

- Other Levels (Hepta, Octa, Nona, Deca ë“± ì¼ë°˜ë ˆë²¨):
  subjects = [ "Listening", "Reading", "Vocabulary", "Grammar" ]
  + always include: [ "READi", "Alex" ]

* Only output the subjects allowed for that level.

### MT vs Term Test Rules:
- Identify current exam type from [Student Data].
- If current exam is **MT**:
  â€¢ Compare only with previous MT values using scores, percentages, subject balance.
  â€¢ If score change is **Â±15**, do NOT call it "ì†Œí­", "ê²½ë¯¸í•œ".
- If current exam is **Term Test or MT3 (Penta)**:
  â€¢ DO NOT compare Term Test **scores** with any MT scores.
  â€¢ Use ONLY rank, and TT-level cohort position to explain in **natural-language interpretation**.
  â€¢ No raw â€œ214/586â€ or â€œí¼ì„¼íƒ€ì¼ 36.52â€ outputs.
  â€¢ If a level-group change exists, interpret adaptation rather than score gain/loss.

### Numeric Grounding Rules (MANDATORY):
- Each section (Listening, Reading, Vocabulary, Grammar, READi, Alex) MUST explicitly cite:
  â€¢ at least one numeric value (score, trend, count, rank)

### Constraints:
- Avoid ì„œì—´ í‘œí˜„ such as â€œìƒìœ„ê¶Œ ì•„ë‹˜â€, â€œì¤‘ê°„ ìˆ˜ì¤€â€, â€œë†’ì§€ ì•ŠìŒâ€.
- No mention of the length of the passage in the 'Reading' section
- Terminology Rule : achievement rate -> 'ì„±ì·¨ìœ¨', When referring to READi: activity rate-> 'ìˆ˜í–‰ë¥ ', Alex -> 'ë…ì„œëŸ‰'
- For Alex: If the data is empty or zero, do NOT describe it as â€œno dataâ€ or â€œmissing information.â€  
  Interpret it as â€œë…ì„œëŸ‰ì´ ì—†ì—ˆìŒâ€ or â€œìµœê·¼ ë…ì„œ í™œë™ì´ ì´ë£¨ì–´ì§€ì§€ ì•Šì•˜ìŒ.â€

### Section Output Rules:
- Create a guide to determine what patterns exist, what the likely causes are, and what points to emphasize.
- bullet-style, one or two explanations each for Listening, Reading, Vocabulary, Grammar, READi, Alex.
- Sentences should end with noun endings (â€œ~ì„â€, â€œ~í•¨â€).
- Finish with â€œìƒë‹´ Pointâ€, â€œìƒë‹´ Pointâ€ MUST be written as ONE single sentence.
    - Write a data-grounded conclusion sentence that includes:
  â€¢ key numeric evidence (e.g., ì ìˆ˜, ìˆ˜í–‰ë¥ , ë…ì„œëŸ‰)
  â€¢ current learning status interpretation
  â€¢ what the instructor should guide or emphasize NEXT for this student.
- Output MUST be valid JSON using the structure below.

{{
  "sections": {{
    "guide": {{
      "id": "guide",
      "title": "ë°ì´í„° í•´ì„ ê°€ì´ë“œ",
      "subjects": [
        {{
          "label": "Phonics",
          "content": ".."
        }},
        ...
      ],
      "counsel_point": {{
        "label": "ìƒë‹´ Point",
        "content": ".."
      }}
    }}
  }}
}}

Below is the information required for generating.

[Case Code]
{case_code}

[Case Guides]
{case_guideline}

[Student Data]
{summary_str}
"""


async def build_instruction_behavior(readonly_ctx: ReadonlyContext) -> str:
    """
    Build instruction for the 'í–‰ë™' section.
    """
    context = await build_counseling_base_context(readonly_ctx)
    case_code = context["case_code"]
    case_guideline = context["case_guideline"]
    summary_str = context["summary_str"]

    return f"""
You generate ONLY the 'í–‰ë™' section of a CANB parent counseling guide in Korean.

Follow these rules:
- Use [Student Data] as the primary source for linking behavior and performance.
- Use [Case Guides] for tone, focus, and strategy hints.
- Do NOT copy example sentences from [Case Guides].
- Do NOT mention case_code or case_name explicitly.
- 'ê¸´ ê¸€', 'ê¸´ ì§€ë¬¸' ë“±ì˜ í‘œí˜„ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

Section (3) í–‰ë™ consists of two parts:

(ìˆ˜ì—… ê´€ì°°)
- 1 to 3 bullet-style sentences.
- Each bullet describes concrete classroom behaviors the instructor should actively observe and note during lessons.
- Suggest to check whether specific behaviors changed and how that links to scores.
- Terminology Rule : 'ë„ì „ ë‚œì´ë„' -> 'ì–´ë ¤ìš´ ë¬¸ì œ'

(í•™ë¶€ëª¨ í™•ì¸ ìš”ì²­)
- 1 to 2 bullet-style sentences.
- Suggest what parents can observe or ask at home, connected to the current performance.

Output requirements:
- Output MUST be valid JSON.
- No markdown code fences, no comments.
- Use this exact structure and Korean keys:
{{
  "sections": {{
    "behavior": {{
      "id": "behavior",
      "title": "í–‰ë™",
      "acts": [
        {{
          "label": "ìˆ˜ì—… ê´€ì°°",
          "items": ["...", "..."]
        }},
        {{
          "label": "í•™ë¶€ëª¨ í™•ì¸ ìš”ì²­",
          "items": ["...", "..."]
        }}
      ]
    }}
  }}
}}

Below is the information required for generating the counseling script.

[Case Code]
{case_code}

[Case Guides]
{case_guideline}

[Student Data]
{summary_str}
"""


async def build_instruction_closing(readonly_ctx: ReadonlyContext) -> str:
    """
    Build instruction for the 'ë§ˆë¬´ë¦¬' section.
    """
    context = await build_counseling_base_context(readonly_ctx)
    case_code = context["case_code"]
    case_guideline = context["case_guideline"]
    summary_str = context["summary_str"]

    return f"""
You generate ONLY the 'ë§ˆë¬´ë¦¬' section in Korean.

Use [Student Data] â€” especially the "learning_recommendation" field â€” to create data-aligned and personalized recommendations.  
Use [Case Guides] for tone and strategic direction.  
Do NOT copy example sentences from Case Guides.  
Do NOT mention case_code or case_name.

Section Rules:
(ì¶”ì²œ í™œë™)
- bullet-style. Maximum 3 bullets.
- Primarily use the information in "learning recommendation" of [Student Data] (e.g., ìŠ¤í‚¬ ê°•í™”, ë…ì„œ ëª©í‘œ ë“±).
- Each bullet MUST follow this format:
  "Activity or Strategy Label: concise one-line purpose or effect"
- Do NOT write full sentences.

### Fallback Rule
- If "learning recommendation" is empty, missing, or does not contain explicit activity/strategy names:
  â€¢ Refer to the "weak_skill" keys in [Student Data].
  â€¢ Generate strategy-based activity labels that focus on strengthening those weak skills.
  â€¢ Use noun-ending style labels and descriptions .
  â€¢ Do NOT invent program names.
  
(ì˜¨ë¼ì¸Â·ë„ì„œ ê°•í™” ë°©í–¥)
- Provide like bullets.
- READi, Alex's action strategy based on data from [Student Data].

(ë§ˆë¬´ë¦¬ ë©˜íŠ¸)
- Provide exactly one short, supportive sentence. 
- Mention which stage student is in: "ì¤€ë¹„/ë„ì•½/íšŒë³µ/ê¸°ì´ˆ í˜•ì„±", and emphasize the child's strengths and potential, briefly outline the division of roles between the academy and home
- The academy says it provides more detailed management and attention.
Output must be valid JSON:

{{
  "sections": {{
    "conclude": {{
      "id": "conclude",
      "title": "ë§ˆë¬´ë¦¬",
      "closing": [
        {{
          "label": "ì¶”ì²œ í™œë™",
          "items": [
              {{ "label": "...", "detail": "..." }}       
            ]
        }},
        {{
          "label": "ì˜¨ë¼ì¸Â·ë„ì„œ ê°•í™” ë°©í–¥",
          "items": [
              {{ "label": "...", "detail": "..." }}
          ]
        }}
      ],
      "finalize": {{
        "label": "ë§ˆë¬´ë¦¬ ë©˜íŠ¸",
        "content": "..."
      }}
    }}
  }}
}}

Below is the information required for generating the counseling script.

[Case Code]
{case_code}

[Case Guides]
{case_guideline}

[Student Data]
{summary_str}
"""

# === ê° ì˜ì—­ë³„ ì—ì´ì „íŠ¸ ìƒì„± === # 
def get_avoided_and_overall_agent() -> LlmAgent:
    return LlmAgent(
        name="counseling_section_avoided_and_overall",
        model=LiteLlm(model=MODEL_GPT_5, response_format=first_schema),
        instruction=build_instruction_avoided_and_overall,
        description="Generates the 'ì§€ì–‘ í‘œí˜„' and 'ì´í‰' sections of the counseling guide.",
        output_key="section_avoided_and_overall",
    )


def get_data_guide_agent() -> LlmAgent:
    return LlmAgent(
        name="counseling_section_data_guide",
        model=LiteLlm(model=MODEL_GPT_5, response_format=second_schema),
        instruction=build_instruction_data_guide,
        description="Generates the 'ë°ì´í„° í•´ì„ ê°€ì´ë“œ' section of the counseling guide.",
        output_key="section_data_guide",
    )


def get_behavior_agent() -> LlmAgent:
    return LlmAgent(
        name="counseling_section_behavior",
        model=LiteLlm(model=MODEL_GPT_5, response_format=third_schema),
        instruction=build_instruction_behavior,
        description="Generates the 'í–‰ë™' section of the counseling guide.",
        output_key="section_behavior",
    )


def get_closing_agent() -> LlmAgent:
    return LlmAgent(
        name="counseling_section_closing",
        model=LiteLlm(model=MODEL_GPT_5, response_format=fourth_schema),
        instruction=build_instruction_closing,
        description="Generates the 'ë§ˆë¬´ë¦¬' section of the counseling guide.",
        output_key="section_closing",
    )

# === (í˜„ì¬ ì‚¬ìš©ì•ˆí•¨, Fallbackìš©) ìµœì¢… ìƒë‹´ ê°€ì´ë“œ ìƒì„± ì—ì´ì „íŠ¸ === # 
def get_counseling_generator_agent() -> LlmAgent:
    """
    Create counseling generator agent that uses outputs from upstream agents.

    - Uses case_guides.yaml as the canonical case guideline source.
    - At runtime, reads `result` from session state to determine case_code,
      extracts only that case's rules block from the YAML, and injects it
      under the [Case Guides] section.
    - Also injects {result} and {summary} from session state into the prompt.
    """

    async def build_instruction(readonly_ctx: ReadonlyContext) -> str:
        """
        Build final monolithic instruction using the shared counseling context.

        ì„¹ì…˜ë³„ ì—ì´ì „íŠ¸ë¥¼ ë³‘ë ¬í™” í•˜ê¸° ìœ„í•´ì„œ í•µì‹¬ ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•.
        """
        context = await build_counseling_base_context(readonly_ctx)
        case_guideline = context["case_guideline"]

        # 1) Inject the case guideline into the template so it's no longer a
        #    {VAR} placeholder and won't be touched by state injection.
        template = COUNSELING_GENERATOR_PROMPT.replace("{CASE_GUIDES_YAML}", case_guideline)

        # 2) Ask ADK's inject_session_state to populate {result} and {summary}
        #    (and any other state-backed placeholders) from the session.
        final_instruction = await inject_session_state(template, readonly_ctx)
        return final_instruction

    # Log the final, runtime-injected instruction just before model call
    # Signature must match BaseLlmFlow._handle_before_model_callback:
    #   callback(callback_context=..., llm_request=...)
    def _before_model_log(callback_context: CallbackContext, llm_request: LlmRequest):
        # Start performance tracking
        tracker = get_tracker()
        tracker.start("counseling_generator_agent")
        logger.info("ğŸ“ Counseling Generator Agent: Starting guide generation (monolithic)...")

        # Debug logging if enabled
        if os.getenv("PROMPT_DEBUG", "0") != "1":
            return None
        try:
            project_root = os.path.abspath(os.path.dirname(__file__) + "/../../..")
            debug_dir = os.path.join(project_root, "output", "debug")
            os.makedirs(debug_dir, exist_ok=True)
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            final_instruction = llm_request.config.system_instruction or ""
            with open(os.path.join(debug_dir, f"counseling_prompt_final_{ts}.txt"), "w", encoding="utf-8") as f:
                f.write(final_instruction)
        except Exception as e:
            # Best-effort logging; don't break execution
            print(f"[PROMPT_DEBUG] Failed to write final instruction: {e}")

    def _after_model_log(callback_context: CallbackContext, llm_response):
        """Track end time and log performance summary."""
        tracker = get_tracker()
        duration = tracker.end("counseling_generator_agent")
        logger.info(f"ğŸ“ Counseling Generator Agent: Completed in {duration:.2f}s")

        # Log overall performance summary
        log_performance_summary()

    return LlmAgent(
        name="counseling_generator_agent",
        model=LiteLlm(model=MODEL_GPT_5),
        instruction=build_instruction,
        description="Generates a counseling guide based on the case guideline and raw data (monolithic single call).",
        output_key="generated_counseling_guide",
        before_model_callback=_before_model_log,
        after_model_callback=_after_model_log,
    )

# === (í˜„ì¬ ì‚¬ìš©) ì„¹ì…˜ë³„ ê²°ê³¼ ë³‘í•© í•¨ìˆ˜ === # 
def _merge_sections_from_state(state: dict) -> dict:
    """Merge section-wise JSON outputs from session state into a final guide dict.
    
    ìµœì¢…ì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¥¼ ë§Œë“ ë‹¤:
        {
          "sections": {
            "avoid": {...},
            "summary": {...},
            "guide": {...},
            "behavior": {...},
            "conclude": {...}
          }
        }
    """
    def _ensure_obj(value, section_name: str) -> dict:
        if value is None:
            raise ValueError(f"Missing section output for {section_name}")
        if isinstance(value, dict):
            return value
        if isinstance(value, str):
            try:
                return json.loads(value)
            except Exception as e:
                raise ValueError(f"Failed to parse JSON for {section_name}: {e}") from e
        raise ValueError(f"Unexpected type for {section_name}: {type(value)}")

    avoided_and_overall = _ensure_obj(
        state.get("section_avoided_and_overall"), "section_avoided_and_overall"
    )
    data_guide = _ensure_obj(
        state.get("section_data_guide"), "section_data_guide"
    )
    behavior = _ensure_obj(
        state.get("section_behavior"), "section_behavior"
    )
    closing = _ensure_obj(state.get("section_closing"), "section_closing")

    merged_sections: dict = {}

    # ê° ì„¹ì…˜ ì—ì´ì „íŠ¸ì˜ ê²°ê³¼ì—ì„œ "sections" ë”•ì…”ë„ˆë¦¬ë§Œ êº¼ë‚´ì„œ ë‹¨ìˆœ ë³‘í•©
    for payload in (avoided_and_overall, data_guide, behavior, closing):
        if not isinstance(payload, dict):
            continue
        sections_obj = payload.get("sections")
        if not isinstance(sections_obj, dict):
            continue
        # ë‹¨ìˆœ merge: ë’¤ì— ì˜¤ëŠ” ê°’ì´ ì•ì˜ ê°’ì„ ë®ì–´ì”€ (ì¶©ëŒ ë‚  ì¼ì€ ê±°ì˜ ì—†ìŒ)
        merged_sections.update(sections_obj)

    return {"sections": merged_sections}

# === (í˜„ì¬ ì‚¬ìš©) ì„¹ì…˜ë³„ ê²°ê³¼ ë³‘í•© ë² ì´ìŠ¤ ì—ì´ì „íŠ¸ === # 
class MergeCounselingSectionsAgent(BaseAgent):
    """Pure-Python agent that merges section outputs into the final 5-section JSON."""

    output_key: str = "generated_counseling_guide"

    async def _run_async_impl(self, ctx):
        tracker = get_tracker()
        tracker.start("counseling_sections_merge")
        state = ctx.session.state
        try:
            # Try to merge section outputs from session state.
            # `merged` is a pure Python dict representing the final JSON structure.
            merged = _merge_sections_from_state(state)

            # For event streaming/logging we still serialize to a pretty JSON string,
            # but in session.state we now store the dict itself so downstream
            final_json = json.dumps(merged, ensure_ascii=False, indent=2)

            # Prepare state delta and content.
            actions = EventActions()
            # Store as dict (JSON object) instead of serialized string.
            actions.state_delta[self.output_key] = merged
            content = types.Content(parts=[types.Part.from_text(text=final_json)])

            event = Event(
                invocation_id=ctx.invocation_id,
                author=self.name,
                branch=ctx.branch,
                content=content,
                actions=actions,
            )
            # Yield a single event containing the merged JSON and state delta.
            yield event

            duration = tracker.end("counseling_sections_merge")
            logger.info(
                "ğŸ§© Counseling Sections Merge: Completed in %.2fs", duration
            )
            # Log overall performance summary for the full parallel pipeline.
            log_performance_summary()
            return
        except Exception as merge_error:
            tracker.end("counseling_sections_merge")
            logger.error(
                "Failed to merge counseling sections: %s",
                merge_error,
            )
            # Offline policy: do not fall back to legacy monolithic prompt.
            # Propagate the error so the client can see that merging failed.
            raise


# Instantiate section agents and the parallel + merge pipeline.
section_avoided_and_overall_agent = get_avoided_and_overall_agent()
section_data_guide_agent = get_data_guide_agent()
section_behavior_agent = get_behavior_agent()
section_closing_agent = get_closing_agent()


def _before_sections_parallel(callback_context: CallbackContext):
    tracker = get_tracker()
    tracker.start("counseling_sections_parallel")
    logger.info(
        "ğŸ§© Counseling Sections Parallel: Starting parallel section generation..."
    )


def _after_sections_parallel(callback_context: CallbackContext):
    tracker = get_tracker()
    duration = tracker.end("counseling_sections_parallel")
    logger.info(
        "ğŸ§© Counseling Sections Parallel: Completed in %.2fs", duration
    )


counseling_sections_parallel_agent = ParallelAgent(
    name="counseling_sections_parallel_agent",
    sub_agents=[
        section_avoided_and_overall_agent,
        section_data_guide_agent,
        section_behavior_agent,
        section_closing_agent,
    ],
    description="Runs counseling sections (ì§€ì–‘+ì´í‰, ë°ì´í„° í•´ì„, í–‰ë™, ë§ˆë¬´ë¦¬) in parallel.",
    before_agent_callback=_before_sections_parallel,
    after_agent_callback=_after_sections_parallel,
)

counseling_parallel_agent = SequentialAgent(
    name="counseling_parallel_counseling_agent",
    description=(
        "Executes the CANB counseling pipeline for sections: "
        "parallel section generators then pure-Python merge into a final 5-section JSON."
    ),
    sub_agents=[
        counseling_sections_parallel_agent,
        MergeCounselingSectionsAgent(name="counseling_sections_merger"),
    ],
)